{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox, pandas as pd, geopandas as gpd, time, numpy as np\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data preparation, removing unwanted characters from geometry\n",
    "\n",
    "data_addresses = gpd.read_file(\"BRW_Adressen_Python.shp\") \n",
    "\n",
    "# A shape file containing ~400k address coordinates of Berlin, obtained from the Berlin Open Data website: \n",
    "# http://fbinter.stadt-berlin.de/fb/?loginkey=showMap&mapId=k_wohnlagenadr2017@senstadt\n",
    "# including classification into relatively poor, mid-level and good residential areas \n",
    "\n",
    "empty_list = []\n",
    "\n",
    "for idx, element in enumerate(data_addresses['geometry']):\n",
    "    \n",
    "    empty_dict = {}\n",
    "    \n",
    "    text = str(element)[12:-1]\n",
    "    \n",
    "    x = float(text.split()[0])\n",
    "    y = float(text.split()[1])\n",
    "    \n",
    "    point = Point((x,y))\n",
    "    \n",
    "    empty_dict['geometry'] = point\n",
    "    empty_dict['address_ID'] = idx\n",
    "    \n",
    "    empty_dict['x'] = x\n",
    "    empty_dict['y'] = y\n",
    "    \n",
    "    empty_list.append(empty_dict)\n",
    "    \n",
    "final_df = pd.DataFrame(empty_list)\n",
    "address_df = gpd.GeoDataFrame(final_df, geometry = final_df['geometry'])\n",
    "address_df.crs = {'init' :'epsg:32633'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same work as before\n",
    "\n",
    "data_trees = gpd.read_file(\"Baeume_gesamt_Python.shp\")\n",
    "\n",
    "# A shape file containing ~360k coordinates of trees, obtained from the Berlin Open Data website: \n",
    "# http://fbinter.stadt-berlin.de/fb/?loginkey=alphaDataStart&alphaDataId=s_wfs_baumbestand@senstadt\n",
    "# including information about species, type, year of planting, crown diameter (in meters), stem diameter (in cm) \n",
    "# and height (in m)\n",
    "\n",
    "# The original file was extended by data from OpenStreetMap Berlin which also included data on supermarkets,\n",
    "# public transportation, ...\n",
    "# http://download.geofabrik.de/europe/germany/berlin.html (\"berlin-latest-free.shp.zip\")\n",
    "\n",
    "empty_list = []\n",
    "\n",
    "for idx, element in enumerate(data_trees['geometry']):\n",
    "    \n",
    "    empty_dict = {}\n",
    "    \n",
    "    text = str(element)[7:-1]\n",
    "    \n",
    "    x = float(text.split()[0])\n",
    "    y = float(text.split()[1])\n",
    "    \n",
    "    point = Point((x,y))\n",
    "    \n",
    "    empty_dict['geometry'] = point\n",
    "    empty_dict['tree_ID'] = idx\n",
    "    \n",
    "    empty_list.append(empty_dict)\n",
    "    \n",
    "final_df = pd.DataFrame(empty_list)\n",
    "tree_df = gpd.GeoDataFrame(final_df, geometry = final_df['geometry'])\n",
    "tree_df.crs = {'init' :'epsg:32633'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "radius = 500 # setting an extent to how big the area to search into should be. Here: 500 metres up, down, left and right\n",
    "# from centre coordinate\n",
    "\n",
    "spatial_index = tree_df.sindex # setting a spatial index which accelerates the computations significantly\n",
    "\n",
    "empty_list = []\n",
    "\n",
    "#for i, row in enumerate(address_df.itertuples(), 1):\n",
    "\n",
    "for i in range(0, len(address_df)-1):\n",
    "\n",
    "    print (i)\n",
    "    \n",
    "    search_point = address_df[address_df['address_ID'] == i] \n",
    "    \n",
    "    address_ID = search_point['address_ID']\n",
    "    \n",
    "    rectangular = Polygon([(float(search_point.x)-radius, (float(search_point.y)-radius)), \n",
    "                           (float(search_point.x)+radius, (float(search_point.y)-radius)), \n",
    "                           (float(search_point.x)+radius, (float(search_point.y)+radius)),\n",
    "                           (float(search_point.x)-radius, (float(search_point.y)+radius))])  \n",
    "    \n",
    "    # creates a rectangular of equal size for each address coordinate \n",
    "    \n",
    "    possible_matches_index = list(spatial_index.intersection(rectangular.bounds)) # reduces the map to an area containing \n",
    "    # nearby coordinates only\n",
    "    \n",
    "    possible_matches = tree_df.iloc[possible_matches_index]\n",
    "    \n",
    "    if possible_matches.empty == False:\n",
    "        \n",
    "        precise_matches = possible_matches[possible_matches.intersects(rectangular)] \n",
    "        \n",
    "        precise_matches['Dist'] = precise_matches.apply(lambda row:  search_point.distance(row.geometry),axis=1)\n",
    "        \n",
    "        # computes the beeline distance between the reference point and all the remaining candidates' coordinates\n",
    "        \n",
    "        index = precise_matches['Dist'].idxmin(axis=1) # returns the index of the row which minimises the distance\n",
    "        final_row = precise_matches.ix[[index]]\n",
    "        final_row['address_ID'] = int(search_point['address_ID'])\n",
    "        final_row['no_trees_within_km'] = len(precise_matches)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        address_fill = int(search_point['address_ID'])\n",
    "        \n",
    "        final_row = {'geometry': [np.nan], 'tree_ID': [np.nan], 'Dist': [np.nan], 'address_ID': [address_fill], 'no_trees_within_km': [np.nan]}\n",
    "        \n",
    "        final_row = pd.DataFrame(data=final_row)\n",
    "        \n",
    "        final_row = final_row.reindex([int(search_point['address_ID'])])\n",
    "    \n",
    "    empty_list.append(final_row)\n",
    "    \n",
    "final_df = pd.concat(empty_list)\n",
    "final_df.to_csv(\"Nearest_Neighbor.csv\", header = True)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
